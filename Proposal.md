# Project Proposal

## Motivation and Objective
The advent of genearative AI is inevitable when generating synthetic data to bypass certain human verification systems. Current liveness detection systems use biometric sensors (e.g. fingerprint, face, voice, etc.) to verify a human user have intricities in being bypassed (e.g. via photos, face masks, voice clones, etc.). The objective of RuHuman is to design a  verification system that exploits the multimodalities of audio data in order to establish a strong multi-factored conviction on deciding if the input is generated by a human or by some other medium (e.g. recording playback).

## State of the Art and Its Limitations

## Novelty & Rationale

## Potential Impact

## Challenges

## Requirements for Success

## Metrics of Success

## Execution Plan

## Related Work
1. Using MFCC Spectrogram/Frequency Domain Analysis to provide different formats to detect Deepfake Audio <br>
A. Hamza et al., "Deepfake Audio Detection via MFCC Features Using Machine Learning," in IEEE Access, vol. 10, pp. 134018-134028, 2022, doi: 10.1109/ACCESS.2022.3231480.

2. Using Prior Speaker Samples to verify the Speaker <br>
A. Pianese, D. Cozzolino, G. Poggi and L. Verdoliva, "Deepfake audio detection by speaker verification," 2022 IEEE International Workshop on Information Forensics and Security (WIFS), Shanghai, China, 2022, pp. 1-6, doi: 10.1109/WIFS55849.2022.9975428.

3. Creating Random Challenges for a Human User to Do but the AI can't Do: D-CAPTCHA <br>
[https://dl.acm.org/doi/fullHtml/10.1145/3579856.3595801](url)

4. Audio + Video Multimodal Learning for Recognition <br>
Y. Mroueh, E. Marcheret and V. Goel, "Deep multimodal learning for Audio-Visual Speech Recognition," 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), South Brisbane, QLD, Australia, 2015, pp. 2130-2134, doi: 10.1109/ICASSP.2015.7178347.


## References
